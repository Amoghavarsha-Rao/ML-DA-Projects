{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "working with data from a portuguese banking institution. The goal is to predict if the client will subscribe a term deposit, which'll be our y-variable for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df = pd.read_csv(r\"C:\\Users\\artix\\Desktop\\Workspace\\pytorchproject\\Datasets\\bank-additional-full.csv\", delimiter = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10,000+ rows have data where some columns have missing values/unknowns, which is about 25% of data, but imputation isn't exactly possible because a lot of it is categorical data and mode imputation might not be the best decision because there's only two categories and might lead to higher inaccuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital            education default housing loan  \\\n",
       "0   56  housemaid  married             basic.4y      no      no   no   \n",
       "2   37   services  married          high.school      no     yes   no   \n",
       "3   40     admin.  married             basic.6y      no      no   no   \n",
       "4   56   services  married          high.school      no      no  yes   \n",
       "6   59     admin.  married  professional.course      no      no   no   \n",
       "\n",
       "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "2  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "3  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "4  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "6  telephone   may         mon  ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "6          1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_check = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y'] #removing rows with unknowns only on string columns\n",
    "excel_df = excel_df[~excel_df[columns_to_check].apply(lambda row: row.str.contains('unknown', case=False, na=False)).any(axis=1)]\n",
    "excel_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the cleaned data, the idea is now to use different models to predict y (80-20 train test split). Models I plan to use atm.\n",
    "1) Logistic Regression with Elastic Net Regularization\n",
    "2) Random Forest Classification\n",
    "3) Gradient Boosting - either XGBoost, LightGBM or CatBoost\n",
    "4) Support Vector Machines\n",
    "5) MLP/ANN\n",
    "6) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6818\n",
      "Epoch [20/100], Loss: 0.6626\n",
      "Epoch [30/100], Loss: 0.6447\n",
      "Epoch [40/100], Loss: 0.6280\n",
      "Epoch [50/100], Loss: 0.6123\n",
      "Epoch [60/100], Loss: 0.5977\n",
      "Epoch [70/100], Loss: 0.5839\n",
      "Epoch [80/100], Loss: 0.5709\n",
      "Epoch [90/100], Loss: 0.5588\n",
      "Epoch [100/100], Loss: 0.5473\n",
      "Test Accuracy: 0.8088\n",
      "Sample predictions: ['no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'yes' 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Elastic Net Regularization\n",
    "# Attempted using pytorch instead of SKLearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = excel_df.drop(columns=['y']) #Dropping all columns except for y\n",
    "y = excel_df['y'] \n",
    "\n",
    "#Aliasing label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "#Performing label encoding on the categorical variables\n",
    "for column in categorical_columns:\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "\n",
    "#Label encoding the target variable separately\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#Train-test split, 80 - 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Performing standardization using StandardScaler for faster gradient descent\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Elastic Net loss function\n",
    "def elastic_net_loss(output, target, model, l1_lambda, l2_lambda):\n",
    "    \n",
    "    bce_loss = nn.BCELoss()(output, target)\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters()) #L1 regularization(sum of absolute weights)\n",
    "    l2_norm = sum(p.pow(2).sum() for p in model.parameters()) #L2 regularization(sum of squared weights)\n",
    "    return bce_loss + l1_lambda * l1_norm + l2_lambda * l2_norm #Combine cross-entropy loss with L1 and L2 regularization\n",
    "\n",
    "#Convert NumPy arrays to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "\n",
    "#Setting Hyperparameters\n",
    "learning_rate = 0.01\n",
    "l1_lambda = 0.001  #L1 regularization weight\n",
    "l2_lambda = 0.001  #L2 regularization weight\n",
    "epochs = 100\n",
    "\n",
    "#Setting Optimizer as Stochastic Gradient Descent(SGD)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = elastic_net_loss(output, y_train_tensor, model, l1_lambda, l2_lambda) #Compute ElasticNet loss (cross-entropy + L1 + L2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}') #Printing loss every 10 epochs too see progress\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "    accuracy = (y_pred_class == torch.tensor(y_test, dtype=torch.float32).view(-1, 1)).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy.item():.4f}')\n",
    "\n",
    "\n",
    "# y_pred_labels = le.inverse_transform(y_pred_class.cpu().numpy().ravel().astype(int)) #converting labels back to original values\n",
    "# print(\"Sample predictions:\", y_pred_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#80% accuracy with Logistic Regression with Elastic Net regularization recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      5304\n",
      "           1       0.77      0.22      0.34       794\n",
      "\n",
      "    accuracy                           0.89      6098\n",
      "   macro avg       0.83      0.60      0.64      6098\n",
      "weighted avg       0.88      0.89      0.86      6098\n",
      "\n",
      "[[5253   51]\n",
      " [ 620  174]]\n",
      "Feature: age, Importance: 0.0101\n",
      "Feature: job, Importance: 0.0015\n",
      "Feature: marital, Importance: 0.0010\n",
      "Feature: education, Importance: 0.0016\n",
      "Feature: default, Importance: 0.0000\n",
      "Feature: housing, Importance: 0.0005\n",
      "Feature: loan, Importance: 0.0003\n",
      "Feature: contact, Importance: 0.0076\n",
      "Feature: month, Importance: 0.0189\n",
      "Feature: day_of_week, Importance: 0.0030\n",
      "Feature: duration, Importance: 0.3276\n",
      "Feature: campaign, Importance: 0.0029\n",
      "Feature: pdays, Importance: 0.0970\n",
      "Feature: previous, Importance: 0.0107\n",
      "Feature: poutcome, Importance: 0.0669\n",
      "Feature: emp.var.rate, Importance: 0.0443\n",
      "Feature: cons.price.idx, Importance: 0.0362\n",
      "Feature: cons.conf.idx, Importance: 0.0542\n",
      "Feature: euribor3m, Importance: 0.1663\n",
      "Feature: nr.employed, Importance: 0.1495\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "X = excel_df.drop(columns=['y']) #Dropping all columns except for y\n",
    "y = excel_df['y'] \n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "#Performing label encoding on the categorical variables\n",
    "for column in categorical_columns:\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "\n",
    "#Label encoding the target variable separately\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#Train-test split, 80 - 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth = 5, random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#calculating accuracy and metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "#also calculating feature importance for an in-depth understanding of data\n",
    "feature_importance = model.feature_importances_\n",
    "for feature, importance in zip(X.columns, feature_importance):\n",
    "    print(f\"Feature: {feature}, Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few inferences:\n",
    "\n",
    "89% accuracy observed with good precision and recall for class 0 (\"no\") but average precision and very poor recall for class 1 (\"yes\"). F1 score is good for class 0 but very poor for class 1. This my be due to the imbalance in datasets between classes as indicated by the support metrics. \n",
    "\n",
    "to remedy this, can try undersampling the majority class (class 0) or the SMOTE algorithm to oversample the minority class. SMOTE might be a better approach because the amount of data for class 1, (which we will make class 0 data equal to) is not too big, and computation time increase from the increased amount of data is not too high. Considering its not too much data either, undersampling class 1 data might cause important data to be lost. Conclusion: use SMOTE on Class 0 data.\n",
    "\n",
    "Feature importance results are interesting beccause the 'default' column has 0 feature importance, which would be countr-intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      5304\n",
      "           1       0.45      0.85      0.59       794\n",
      "\n",
      "    accuracy                           0.85      6098\n",
      "   macro avg       0.71      0.85      0.75      6098\n",
      "weighted avg       0.91      0.85      0.86      6098\n",
      "\n",
      "[[4487  817]\n",
      " [ 121  673]]\n",
      "Feature: age, Importance: 0.0016\n",
      "Feature: job, Importance: 0.0041\n",
      "Feature: marital, Importance: 0.0026\n",
      "Feature: education, Importance: 0.0032\n",
      "Feature: default, Importance: 0.0000\n",
      "Feature: housing, Importance: 0.0149\n",
      "Feature: loan, Importance: 0.0044\n",
      "Feature: contact, Importance: 0.0529\n",
      "Feature: month, Importance: 0.0227\n",
      "Feature: day_of_week, Importance: 0.0048\n",
      "Feature: duration, Importance: 0.3385\n",
      "Feature: campaign, Importance: 0.0036\n",
      "Feature: pdays, Importance: 0.0351\n",
      "Feature: previous, Importance: 0.0059\n",
      "Feature: poutcome, Importance: 0.0270\n",
      "Feature: emp.var.rate, Importance: 0.0788\n",
      "Feature: cons.price.idx, Importance: 0.0458\n",
      "Feature: cons.conf.idx, Importance: 0.0647\n",
      "Feature: euribor3m, Importance: 0.1385\n",
      "Feature: nr.employed, Importance: 0.1507\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification but with oversampling on class 0 data using SMOTE\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "X = excel_df.drop(columns=['y']) #Dropping all columns except for y\n",
    "y = excel_df['y'] \n",
    "\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "#Performing label encoding on the categorical variables\n",
    "for column in categorical_columns:\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "\n",
    "#Label encoding the target variable separately\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# #Train-test split, 80 - 20\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth = 5, random_state=1)\n",
    "model.fit(X_train_res,y_train_res)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#calculating accuracy and metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "#also calculating feature importance for an in-depth understanding of data\n",
    "feature_importance = model.feature_importances_\n",
    "for feature, importance in zip(X.columns, feature_importance):\n",
    "    print(f\"Feature: {feature}, Importance: {importance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
